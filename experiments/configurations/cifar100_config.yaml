# Outer Optimization (Loss Discovery) Hyper-parameters
population_size: 25
num_generations: 50
crossover_rate: 0.7
mutation_rate: 0.25
elitism_rate: 0.05
tournament_size: 4
max_height: 10
init_min_height: 2
init_max_height: 4

# Inner Optimization (Loss Optimization) Hyper-parameters
meta_gradient_steps: 250
meta_learning_rate: 0.001
inner_gradient_steps: 1
base_gradient_steps: 500
base_learning_rate: 0.01
base_weight_decay: 0.0005
base_momentum: 0.9
base_nesterov: True
base_batch_size: 128

# Loss Function Learning Filter Hyper-parameters
filter_significant_digits: 2
filter_rejection_threshold: 0.6
filter_gradient_steps: 1000
filter_sample_size: 100

# Loss Function Learning Objectives
outer_objective_name: "MultiErrorRate"
inner_objective_name: "NLLLoss"

# Meta Testing Hyper-parameters
testing_gradient_steps: 150000
testing_learning_rate: 0.01
testing_weight_decay: 0.0005
testing_momentum: 0.9
testing_nesterov: True
testing_batch_size: 128
testing_milestones: [100000, 135000]
testing_gamma: 0.1

# Base Network Hyper-parameters
base_network_parameters:
  output_dim: 100

# Experiment Settings
output_path: results/cifar100/
verbose: 2
